{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += \"/home/takamichi-lab3/kenkyu/venv/bin/pip\"\n",
    "import pandas as pd \n",
    "from kl_set import calculate_kl_divergence_sum, count_topic_tag_proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def _validate_set(df, num_sample_per_set, reference_prob, kl_threshold):\n",
    "    ok_set_id_list = []\n",
    "    for set_id in df['set_id'].unique():\n",
    "        df_sub = df[df['set_id'] == set_id]\n",
    "\n",
    "        # check the number of samples\n",
    "        if len(df_sub) != num_sample_per_set: \n",
    "            continue    \n",
    "        # check the number of unique files\n",
    "        if df_sub[\"filename\"].nunique() != num_sample_per_set: \n",
    "            continue\n",
    "        # check the KL divergence\n",
    "        partial_prob = count_topic_tag_proportions(df_sub)\n",
    "        if calculate_kl_divergence_sum(reference_prob, partial_prob) > kl_threshold:\n",
    "            continue\n",
    "\n",
    "        ok_set_id_list.append(set_id)\n",
    "\n",
    "    return ok_set_id_list\n",
    "\n",
    "\n",
    "def assign_set(\n",
    "    df_org: pd.DataFrame,\n",
    "    reference_prob: dict,\n",
    "    kl_threshold: float,\n",
    "    num_sample_per_delay: 2,\n",
    "    num_trial: int = 1000,\n",
    "):\n",
    "    df = df_org.copy()\n",
    "\n",
    "    # extract delay value from filename\n",
    "    df['delay_value'] = df['filename'].str.extract(r'delay([\\-]?\\d+\\.\\d+)')[0].astype(float)\n",
    "    delay_value_list = df['delay_value'].unique()\n",
    "    assert len(delay_value_list) % num_sample_per_delay == 0, 'The number of samples must be a multiple of num_sample_per_delay.'\n",
    "\n",
    "    df[\"set_id\"] = None\n",
    "    num_sample_per_set = num_sample_per_delay * len(delay_value_list)\n",
    "    num_set = len(df) // num_sample_per_set\n",
    "    set_id_list = [f\"set{i+1}\" for i in range(num_set)]\n",
    "\n",
    "    n_trial = 0\n",
    "    num_remaining_list = []\n",
    "    while df[\"set_id\"].isnull().any():\n",
    "        df_loop = df[df[\"set_id\"].isnull()].sample(frac=1)\n",
    "\n",
    "        # assign set_id for each delay value\n",
    "        for delay in delay_value_list:   \n",
    "            _df = df_loop[df_loop['delay_value'] == delay]\n",
    "\n",
    "            for idx in range(len(_df) // num_sample_per_delay):\n",
    "                df.loc[_df.index[idx*num_sample_per_delay:(idx+1)*num_sample_per_delay], \"set_id\"] = set_id_list[idx]\n",
    "\n",
    "        # validate set (True if the set is valid)\n",
    "        ok_set_id_list = _validate_set(\n",
    "            df, num_sample_per_set, reference_prob, kl_threshold)\n",
    "\n",
    "        # remove invalid set_id\n",
    "        df[\"set_id\"] = df[\"set_id\"].apply(lambda x: x if x in ok_set_id_list else None)\n",
    "        set_id_list = list(set(set_id_list) - set(ok_set_id_list))\n",
    "        num_remaining_list.append(len(df[df['set_id'].isnull()]))\n",
    "\n",
    "        print(f\"{n_trial}-th trial: {num_remaining_list[-1]} / {len(df)}\")\n",
    " \n",
    "        n_trial += 1\n",
    "        if n_trial > num_trial:\n",
    "            print(\"The number of trials has reached the limit. Stop the process.\")\n",
    "            break\n",
    "\n",
    "        if len(num_remaining_list) > 10:\n",
    "            if all([num_remaining_list[i] == num_remaining_list[-1] for i in range(-10, 0)]):\n",
    "                print(\"The number of remaining samples is not decreasing. Stop the process.\")\n",
    "                break\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th trial: 9456 / 25080\n",
      "1-th trial: 4536 / 25080\n",
      "2-th trial: 2856 / 25080\n",
      "3-th trial: 2040 / 25080\n",
      "4-th trial: 1632 / 25080\n",
      "5-th trial: 1296 / 25080\n",
      "6-th trial: 1176 / 25080\n",
      "7-th trial: 1032 / 25080\n",
      "8-th trial: 960 / 25080\n",
      "9-th trial: 912 / 25080\n",
      "10-th trial: 864 / 25080\n",
      "11-th trial: 816 / 25080\n",
      "12-th trial: 792 / 25080\n",
      "13-th trial: 768 / 25080\n",
      "14-th trial: 768 / 25080\n",
      "15-th trial: 744 / 25080\n",
      "16-th trial: 744 / 25080\n",
      "17-th trial: 720 / 25080\n",
      "18-th trial: 720 / 25080\n",
      "19-th trial: 672 / 25080\n",
      "20-th trial: 672 / 25080\n",
      "21-th trial: 672 / 25080\n",
      "22-th trial: 672 / 25080\n",
      "23-th trial: 672 / 25080\n",
      "24-th trial: 672 / 25080\n",
      "25-th trial: 672 / 25080\n",
      "26-th trial: 672 / 25080\n",
      "27-th trial: 672 / 25080\n",
      "28-th trial: 672 / 25080\n",
      "The number of remaining samples is not decreasing. Stop the process.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "df_all = pd.read_csv('comment_list.csv')\n",
    "\n",
    "# statistics of total data\n",
    "reference_prob = count_topic_tag_proportions(df_all)\n",
    "df_sub = df_all.copy()\n",
    "\n",
    "# assign set_id\n",
    "df = assign_set(\n",
    "    df_sub, reference_prob=reference_prob, \n",
    "    kl_threshold=0.05, num_sample_per_delay=2)\n",
    "df.to_csv('comment_list_with_set_id.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
